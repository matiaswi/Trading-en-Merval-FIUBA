{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uwWmkUuVf3m"
   },
   "source": [
    "## Importación de Librerías\n",
    "Importamos la lista de librerías que vamos a utilizar, y que ya están listadas en otro archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4480,
     "status": "ok",
     "timestamp": 1655059098587,
     "user": {
      "displayName": "trading fiuba",
      "userId": "07407005126005280343"
     },
     "user_tz": 180
    },
    "id": "Iey4wmHWVjgM",
    "outputId": "8005f8f7-f710-4fbe-f032-15af95e8de83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \".\\\\00. Importación de Librerías\\\\Librerias_para_importar.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeOdQ5rpOyeI"
   },
   "source": [
    "## Definición de funciones\n",
    "Importamos las funciones definidas en otro archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "lldMXNPTAJE6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \".\\\\00. Definición de funciones\\\\Funciones_definidas.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTK6Li-0SqSP"
   },
   "source": [
    "## Estructuración y Limpieza de los Datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "ryuTC-7YSivF"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\".\\\\0. Datos de Entrada\\\\Datos_Completos.csv\")\n",
    "\n",
    "# Renombramos las columnas:\n",
    "data = data.rename(columns={'fecha': \"fecha_IOL\",'apertura': \"open\",'cierre': \"close\",'máximo': \"high\", 'mínimo': \"low\" }) \n",
    "agregado_al_nombre_del_archivo = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRATAMIENTO DE LOS DÍAS CON TODAS SUS COTIZACIONES NULAS ( = 0 ):\n",
    "\n",
    "data[\"sin_cotizacion\"] = np.where( (data[\"open\"]==0) & (data[\"close\"]==0) & (data[\"high\"]==0) & (data[\"low\"]==0) , 1, 0)\n",
    "print(\"La cantidad de filas que tienen todas sus cotizaciones nulas es:\", data[data.sin_cotizacion == 1].shape[0], '\\n' )\n",
    "data = data[data.sin_cotizacion == 0]  # Aquí se eliminan las filas que tienen cotizaciones nulas.\n",
    "data = data.drop([\"sin_cotizacion\"], axis=1)\n",
    "\n",
    "\n",
    "# TRATAMIENTO DE LOS DÍAS CON COTIZACIONES DE CLOSE o OPEN NULAS ( = 0 ):\n",
    "\n",
    "data[\"sin_cotizacion\"] = np.where( ((data[\"open\"]==0) | (data[\"close\"]==0)), 1, 0)\n",
    "print(\"La cantidad de filas que tienen cotizaciones de Close o Open nulas es:\", data[data.sin_cotizacion == 1].shape[0], '\\n' )\n",
    "data = data[data.sin_cotizacion == 0]  # Aquí se eliminan las filas que tienen cotizaciones nulas.\n",
    "data = data.drop([\"sin_cotizacion\"], axis=1)\n",
    "\n",
    "\n",
    "# TRATAMIENTO DE LOS VALORES de VOLUMEN NULO (= 0) (Utilizar sólo uno de los siguientes métodos):\n",
    "print(\"La cantidad de filas que tienen Volumen(t) nulo es:\", data[data.volumen == 0].shape[0] )\n",
    "\n",
    "# # Eliminamos aquellas filas que tienen Volumen igual a cero (muchas veces corresponden a días feriados o similares, salvo cuando hay errores en la\n",
    "# # base de datos (como el caso de CEPU) o cuando la acción no tiene transacciones pero se trata de un día hábil):\n",
    "# data = data[data.volumen != 0] \n",
    "\n",
    "# En aquellas filas donde el Volumen es cero, se reemplaza el cero por un número 'muy bajo':\n",
    "numero_muy_bajo = 1000\n",
    "data[\"volumen\"].replace(0, numero_muy_bajo, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las filas repetidas:\n",
    "\n",
    "print(\"La cantidad de filas repetidas es:\", len(data[data.duplicated()].index) )\n",
    "data = data.drop(data[data.duplicated()].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos todas las filas donde para una determinada acción exista más de 1 fila con la misma fecha:\n",
    "\n",
    "data[\"fecha_aux\"] = list(map(lambda x: x[:10], data[\"fecha_IOL\"]))\n",
    "data[\"concatenado\"] = data[\"titulo\"] + \"--\" + data[\"fecha_aux\"]\n",
    "concatenados_repetidos = list(data[\"concatenado\"].value_counts() [data[\"concatenado\"].value_counts() != 1].index)\n",
    "indices_a_eliminar = data [data[\"concatenado\"].isin (concatenados_repetidos)].index\n",
    "\n",
    "if len(concatenados_repetidos) != 0:\n",
    "    for fecha, cantidad in data.loc[indices_a_eliminar] [\"fecha_aux\"].value_counts().items():\n",
    "        print(\"Se eliminaron \", cantidad, \" filas repetidas con la fecha:\", fecha)\n",
    "else:\n",
    "    print(\"Se encontraron  0  filas con la fecha repetida para un mismo título.\")\n",
    "\n",
    "data = data.drop (indices_a_eliminar, axis=0)   # Acá eliminamos las filas.\n",
    "\n",
    "data = data.drop (['fecha_aux'], axis=1)\n",
    "data = data.drop (['concatenado'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "jBdH-mlhShXr"
   },
   "outputs": [],
   "source": [
    "# Formateamos la Fecha para que se muestre con el formato correcto:\n",
    "\n",
    "fecha = []\n",
    "año = []\n",
    "mes = []\n",
    "dia = []\n",
    "\n",
    "for i in data.fecha_IOL:\n",
    "    año.append(i[0:4])\n",
    "    mes.append(i[5:7])\n",
    "    dia.append(i[8:10])\n",
    "    fecha.append(i[0:i.find(\"T\")])\n",
    "    \n",
    "data [\"año\"] = [int(i) for i in año]\n",
    "data [\"mes\"] = [int(i) for i in mes]  \n",
    "data [\"dia\"] = [int(i) for i in dia] \n",
    "data [\"fecha\"] = pd.to_datetime(fecha, dayfirst=True)\n",
    "data[\"dia_de_semana\"] = [i.weekday() + 1 for i in data.fecha]  # Asignamos el 1 a los días Lunes y el 5 a los días Viernes.\n",
    "\n",
    "data.fecha_IOL = pd.to_datetime(data.fecha_IOL, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1654449709468,
     "user": {
      "displayName": "trading fiuba",
      "userId": "07407005126005280343"
     },
     "user_tz": 180
    },
    "id": "3wUcy7Ur1eeZ",
    "outputId": "61bd6140-9598-4e59-c7ed-f75b704cf5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de filas que tienen High(t) nulo es: 3\n",
      "La cantidad de filas que tienen Low(t) nulo es: 3 \n",
      "\n",
      "La cantidad de filas que tiene el error en que High(t) < Open(t) es: 0\n",
      "La cantidad de filas que tiene el error en que High(t) < Close(t) es: 39\n",
      "La cantidad de filas que tiene el error en que Low(t) > Close(t) es: 25\n",
      "La cantidad de filas que tiene el error en que Low(t) > Open(t) es: 0\n"
     ]
    }
   ],
   "source": [
    "# TRATAMIENTO DE LOS ERRORES DE COTIZACIÓN EN LA BASE DE DATOS:\n",
    "\n",
    "# - Cuando High(t) = 0  ó  cuando Low(t) = 0 :\n",
    "\n",
    "print(\"La cantidad de filas que tienen High(t) nulo es:\", data[data.high == 0].shape[0] )\n",
    "print(\"La cantidad de filas que tienen Low(t) nulo es:\", data[data.low == 0].shape[0], '\\n' )\n",
    "\n",
    "lista_de_df = []\n",
    "for accion in data.groupby(['titulo']).groups.keys():\n",
    "  df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "\n",
    "  # Se reemplaza los valores iguales a cero (0) de High(t) y de Low(t) por su valor anterior:\n",
    "  df_aux[\"high\"].replace(to_replace=0, method='ffill', inplace=True)\n",
    "  df_aux[\"low\"].replace(to_replace=0, method='ffill', inplace=True)\n",
    "\n",
    "  lista_de_df.append(df_aux)\n",
    "\n",
    "data = pd.concat(lista_de_df, axis=0)\n",
    "data = data.sort_index()\n",
    "\n",
    "\n",
    "\n",
    "# - Cuando High(t) < Open(t)  ó  cuando High(t) < Close(t)  ó  cuando Low(t) > Close(t)  ó  cuando Low(t) > Open(t):\n",
    "\n",
    "data[\"error_en_High_tipo_1\"] = np.where( data[\"high\"] < data[\"open\"]  , 1, 0)\n",
    "data[\"error_en_High_tipo_2\"] = np.where( data[\"high\"] < data[\"close\"]  , 1, 0)\n",
    "data[\"error_en_Low_tipo_1\"] = np.where( data[\"low\"] > data[\"close\"]  , 1, 0)\n",
    "data[\"error_en_Low_tipo_2\"] = np.where( data[\"low\"] > data[\"open\"]  , 1, 0)\n",
    "\n",
    "print(\"La cantidad de filas que tiene el error en que High(t) < Open(t) es:\", data[data[\"error_en_High_tipo_1\"] == 1].shape[0] )\n",
    "print(\"La cantidad de filas que tiene el error en que High(t) < Close(t) es:\", data[data[\"error_en_High_tipo_2\"] == 1].shape[0] )\n",
    "print(\"La cantidad de filas que tiene el error en que Low(t) > Close(t) es:\", data[data[\"error_en_Low_tipo_1\"] == 1].shape[0] )\n",
    "print(\"La cantidad de filas que tiene el error en que Low(t) > Open(t) es:\", data[data[\"error_en_Low_tipo_2\"] == 1].shape[0] )\n",
    "\n",
    "data[\"high\"] = np.where( data[\"error_en_High_tipo_1\"] == 1 , data[\"open\"], data[\"high\"] )\n",
    "data[\"high\"] = np.where( data[\"error_en_High_tipo_2\"] == 1 , data[\"close\"], data[\"high\"] )\n",
    "data[\"low\"] = np.where( data[\"error_en_Low_tipo_1\"] == 1 , data[\"close\"], data[\"low\"] )\n",
    "data[\"low\"] = np.where( data[\"error_en_Low_tipo_2\"] == 1 , data[\"open\"], data[\"low\"] )\n",
    "\n",
    "data = data.drop([\"error_en_High_tipo_1\"], axis=1)\n",
    "data = data.drop([\"error_en_High_tipo_2\"], axis=1)\n",
    "data = data.drop([\"error_en_Low_tipo_1\"], axis=1)\n",
    "data = data.drop([\"error_en_Low_tipo_2\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVFBTkVeJEVR"
   },
   "source": [
    "## Agregado de Features Externos al Merval (variables macroeconómicas, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "xw3FQyESsXL7"
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos del Dólar CCL \n",
    "\n",
    "dolar_ccl = pd.read_excel(\".\\\\0. Datos de Entrada\\\\dolar_ccl.xlsx\")\n",
    "dolar_ccl.sort_values( by=[\"fecha\"], ascending = True, inplace=True )   # Ordenamos por 'fecha' de la más antigua a la más reciente.\n",
    "lista_completa_de_fechas = pd.date_range( min(data.fecha), max(data.fecha) )  # Creamos un listado con todas las fechas que utilizaremos.\n",
    "df_fechas_completas = pd.DataFrame( {\"fecha\": lista_completa_de_fechas} )\n",
    "dolar_ccl = df_fechas_completas.merge( dolar_ccl, on = \"fecha\", how = 'left' )\n",
    "dolar_ccl = dolar_ccl.fillna(method = 'ffill')  # Completamos los NaN con los valores del dólar del día anterior.\n",
    "dolar_ccl = dolar_ccl.fillna(method = 'bfill')  # Completamos los valores de las primeras fechas para los cuales no tenemos datos con los valores del dólar del día siguiente.\n",
    "\n",
    "dolar_ccl[\"valor_promedio\"] =  np.where(dolar_ccl[\"valor_de_venta\"] == 0, dolar_ccl[\"valor_de_compra\"],\n",
    "                                           dolar_ccl[['valor_de_compra','valor_de_venta']].mean(axis=1))\n",
    "\n",
    "# Eliminamos las fechas repetidas:\n",
    "for fecha_repetida in (dolar_ccl.fecha.value_counts()[ dolar_ccl.fecha.value_counts() >= 2 ]).index :\n",
    "    lista_de_indices_a_eliminar = dolar_ccl [dolar_ccl.fecha == fecha_repetida].index[ 0 : (len(dolar_ccl [dolar_ccl.fecha == fecha_repetida]) -1 ) ]\n",
    "    dolar_ccl = dolar_ccl.drop( lista_de_indices_a_eliminar, axis=0)\n",
    "dolar_ccl = dolar_ccl.reset_index(drop = True)\n",
    "\n",
    "# Agregamos los datos al DataFrame 'data' :\n",
    "data = data.merge( dolar_ccl[[\"fecha\", \"valor_promedio\", \"valor_de_compra\", \"valor_de_venta\" ]], on = \"fecha\", how = 'left' )\n",
    "data.rename(columns = {'valor_promedio':'dolar_ccl', 'valor_de_compra':'dolar_ccl_compra', 'valor_de_venta':'dolar_ccl_venta',}, inplace = True)   # Le cambiamos el nombre a las columnas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "JolZzIM42utO"
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos del Dólar Blue\n",
    "\n",
    "dolar_blue = pd.read_excel(\".\\\\0. Datos de Entrada\\\\dolar_blue.xlsx\")\n",
    "dolar_blue.rename(columns={'Fecha':'fecha', 'Compra':'valor_de_compra', 'Venta':'valor_de_venta'}, inplace=True)\n",
    "dolar_blue.sort_values( by=[\"fecha\"], ascending = True, inplace=True )   # Ordenamos por 'fecha' de la más antigua a la más reciente.\n",
    "lista_completa_de_fechas = pd.date_range( min(data.fecha), max(data.fecha) )  # Creamos un listado con todas las fechas que utilizaremos.\n",
    "df_fechas_completas = pd.DataFrame( {\"fecha\": lista_completa_de_fechas} )\n",
    "dolar_blue = df_fechas_completas.merge( dolar_blue, on = \"fecha\", how = 'left' )\n",
    "dolar_blue = dolar_blue.fillna(method = 'ffill')  # Completamos los NaN con los valores del dólar del día anterior.\n",
    "dolar_blue = dolar_blue.fillna(method = 'bfill')  # Completamos los valores de las primeras fechas para los cuales no tenemos datos con los valores del dólar del día siguiente.\n",
    "\n",
    "dolar_blue[\"valor_promedio\"] = dolar_blue[['valor_de_compra','valor_de_venta']].mean(axis=1)\n",
    "\n",
    "# Eliminamos las fechas repetidas:\n",
    "for fecha_repetida in (dolar_blue.fecha.value_counts()[ dolar_blue.fecha.value_counts() >= 2 ]).index :\n",
    "    lista_de_indices_a_eliminar = dolar_blue [dolar_blue.fecha == fecha_repetida].index[ 0 : (len(dolar_blue [dolar_blue.fecha == fecha_repetida]) -1 ) ]\n",
    "    dolar_blue = dolar_blue.drop( lista_de_indices_a_eliminar, axis=0)\n",
    "dolar_blue = dolar_blue.reset_index(drop = True)\n",
    "\n",
    "# Agregamos los datos al DataFrame 'data' :\n",
    "data = data.merge( dolar_blue[[\"fecha\", \"valor_promedio\", \"valor_de_compra\", \"valor_de_venta\" ]], on = \"fecha\", how = 'left' )\n",
    "data.rename(columns = {'valor_promedio':'dolar_blue', 'valor_de_compra':'dolar_blue_compra', 'valor_de_venta':'dolar_blue_venta',}, inplace = True)   # Le cambiamos el nombre a las columnas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "vxvACTpk-KY6"
   },
   "outputs": [],
   "source": [
    "# Creamos para cada acción/título las variables de entrada 'derivadas' a partir de los datos externos (macroeconómicos, etc):\n",
    "\n",
    "lista_de_df = []\n",
    "\n",
    "for accion in data.groupby(['titulo']).groups.keys():\n",
    "    df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "\n",
    "\n",
    "    df_aux [\"dolar_blue(t-1)/dolar_blue(t-2)\"] = df_aux [\"dolar_blue\"].shift(1) / df_aux [\"dolar_blue\"].shift(2)\n",
    "    df_aux [\"dolar_blue(t-1)/dolar_blue(t-3)\"] = df_aux [\"dolar_blue\"].shift(1) / df_aux [\"dolar_blue\"].shift(3)\n",
    "    df_aux [\"dolar_blue(t-1)/dolar_blue(t-5)\"] = df_aux [\"dolar_blue\"].shift(1) / df_aux [\"dolar_blue\"].shift(5)\n",
    "    df_aux [\"dolar_blue(t-1)/dolar_blue(t-10)\"] = df_aux [\"dolar_blue\"].shift(1) / df_aux [\"dolar_blue\"].shift(10)\n",
    "    df_aux [\"dolar_blue(t-1)/dolar_blue(t-20)\"] = df_aux [\"dolar_blue\"].shift(1) / df_aux [\"dolar_blue\"].shift(20)\n",
    "    df_aux [\"dolar_blue(t-1)/dolar_blue(t-50)\"] = df_aux [\"dolar_blue\"].shift(1) / df_aux [\"dolar_blue\"].shift(50)\n",
    "\n",
    "    df_aux [\"dolar_ccl(t-1)/dolar_ccl(t-2)\"] = df_aux [\"dolar_ccl\"].shift(1) / df_aux [\"dolar_ccl\"].shift(2)\n",
    "    df_aux [\"dolar_ccl(t-1)/dolar_ccl(t-3)\"] = df_aux [\"dolar_ccl\"].shift(1) / df_aux [\"dolar_ccl\"].shift(3)\n",
    "    df_aux [\"dolar_ccl(t-1)/dolar_ccl(t-5)\"] = df_aux [\"dolar_ccl\"].shift(1) / df_aux [\"dolar_ccl\"].shift(5)\n",
    "    df_aux [\"dolar_ccl(t-1)/dolar_ccl(t-10)\"] = df_aux [\"dolar_ccl\"].shift(1) / df_aux [\"dolar_ccl\"].shift(10)\n",
    "    df_aux [\"dolar_ccl(t-1)/dolar_ccl(t-20)\"] = df_aux [\"dolar_ccl\"].shift(1) / df_aux [\"dolar_ccl\"].shift(20)\n",
    "    df_aux [\"dolar_ccl(t-1)/dolar_ccl(t-50)\"] = df_aux [\"dolar_ccl\"].shift(1) / df_aux [\"dolar_ccl\"].shift(50)\n",
    "\n",
    "    df_aux [\"spread_dolar_blue(t-1)\"] = (df_aux [\"dolar_blue_venta\"].shift(1) - df_aux [\"dolar_blue_compra\"].shift(1)) / df_aux [\"dolar_blue\"].shift(1)\n",
    "    df_aux [\"spread_dolar_ccl(t-1)\"] = (df_aux [\"dolar_ccl_venta\"].shift(1) - df_aux [\"dolar_ccl_compra\"].shift(1)) / df_aux [\"dolar_ccl\"].shift(1)\n",
    "    df_aux [\"spread_dolar_ccl(t-1)\"] = np.where( df_aux [\"spread_dolar_ccl(t-1)\"] == - 1, 0, df_aux [\"spread_dolar_ccl(t-1)\"])\n",
    "    \n",
    "    \n",
    "    # EMA (Exponencial Móvil Simple): \n",
    "\n",
    "    df_aux['EMA_dolar_ccl_k=3(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,3)\n",
    "    df_aux['EMA_dolar_ccl_k=10(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,10)\n",
    "    df_aux['EMA_dolar_ccl_k=5(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,5)\n",
    "    df_aux['EMA_dolar_ccl_k=2(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,2)\n",
    "    df_aux['EMA_dolar_ccl_k=15(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,15)\n",
    "    df_aux['EMA_dolar_ccl_k=20(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,20)\n",
    "    df_aux['EMA_dolar_ccl_k=25(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,25)\n",
    "    df_aux['EMA_dolar_ccl_k=30(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,30)\n",
    "    df_aux['EMA_dolar_ccl_k=40(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,40)\n",
    "    df_aux['EMA_dolar_ccl_k=50(t)'] = ta.trend.ema_indicator(df_aux.dolar_ccl,50)\n",
    "\n",
    "    df_aux['EMA_dolar_blue_k=3(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,3)\n",
    "    df_aux['EMA_dolar_blue_k=10(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,10)\n",
    "    df_aux['EMA_dolar_blue_k=5(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,5)\n",
    "    df_aux['EMA_dolar_blue_k=2(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,2)\n",
    "    df_aux['EMA_dolar_blue_k=15(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,15)\n",
    "    df_aux['EMA_dolar_blue_k=20(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,20)\n",
    "    df_aux['EMA_dolar_blue_k=25(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,25)\n",
    "    df_aux['EMA_dolar_blue_k=30(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,30)\n",
    "    df_aux['EMA_dolar_blue_k=40(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,40)\n",
    "    df_aux['EMA_dolar_blue_k=50(t)'] = ta.trend.ema_indicator(df_aux.dolar_blue,50)\n",
    "\n",
    "    df_aux [\"EMA_dolar_blue_k=5(t-1)/EMA_dolar_blue_k=5(t-2)\"] = df_aux [\"EMA_dolar_blue_k=5(t)\"].shift(1) / df_aux [\"EMA_dolar_blue_k=5(t)\"].shift(2)\n",
    "    df_aux [\"EMA_dolar_blue_k=5(t-1)/dolar_blue(t-1)\"] = df_aux [\"EMA_dolar_blue_k=5(t)\"].shift(1) / df_aux [\"dolar_blue\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_blue_k=5(t-3)/dolar_blue(t-1)\"] = df_aux [\"EMA_dolar_blue_k=5(t)\"].shift(3) / df_aux [\"dolar_blue\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_blue_k=5(t-5)/dolar_blue(t-1)\"] = df_aux [\"EMA_dolar_blue_k=5(t)\"].shift(5) / df_aux [\"dolar_blue\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_blue_k=3(t-1)/EMA_dolar_blue_k=3(t-2)\"] = df_aux [\"EMA_dolar_blue_k=3(t)\"].shift(1) / df_aux [\"EMA_dolar_blue_k=3(t)\"].shift(2)\n",
    "    df_aux [\"EMA_dolar_blue_k=10(t-1)/EMA_dolar_blue_k=10(t-2)\"] = df_aux [\"EMA_dolar_blue_k=10(t)\"].shift(1) / df_aux [\"EMA_dolar_blue_k=10(t)\"].shift(2)\n",
    "    df_aux [\"EMA_dolar_blue_k=40(t-1)/dolar_blue(t-1)\"] = df_aux[\"EMA_dolar_blue_k=40(t)\"].shift(1) / df_aux[\"dolar_blue\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_blue_k=30(t-1)/dolar_blue(t-1)\"] = df_aux[\"EMA_dolar_blue_k=30(t)\"].shift(1) / df_aux[\"dolar_blue\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_blue_k=15(t-1)/dolar_blue(t-1)\"] = df_aux[\"EMA_dolar_blue_k=15(t)\"].shift(1) / df_aux[\"dolar_blue\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_blue_k=20(t-1)/dolar_blue(t-1)\"] = df_aux[\"EMA_dolar_blue_k=20(t)\"].shift(1) / df_aux[\"dolar_blue\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_blue_k=10(t-1)/dolar_blue(t-1)\"] = df_aux[\"EMA_dolar_blue_k=10(t)\"].shift(1) / df_aux[\"dolar_blue\"].shift(1)\n",
    "\n",
    "    df_aux [\"EMA_dolar_ccl_k=5(t-1)/EMA_dolar_ccl_k=5(t-2)\"] = df_aux [\"EMA_dolar_ccl_k=5(t)\"].shift(1) / df_aux [\"EMA_dolar_ccl_k=5(t)\"].shift(2)\n",
    "    df_aux [\"EMA_dolar_ccl_k=5(t-1)/dolar_ccl(t-1)\"] = df_aux [\"EMA_dolar_ccl_k=5(t)\"].shift(1) / df_aux [\"dolar_ccl\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_ccl_k=5(t-3)/dolar_ccl(t-1)\"] = df_aux [\"EMA_dolar_ccl_k=5(t)\"].shift(3) / df_aux [\"dolar_ccl\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_ccl_k=5(t-5)/dolar_ccl(t-1)\"] = df_aux [\"EMA_dolar_ccl_k=5(t)\"].shift(5) / df_aux [\"dolar_ccl\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_ccl_k=3(t-1)/EMA_dolar_ccl_k=3(t-2)\"] = df_aux [\"EMA_dolar_ccl_k=3(t)\"].shift(1) / df_aux [\"EMA_dolar_ccl_k=3(t)\"].shift(2)\n",
    "    df_aux [\"EMA_dolar_ccl_k=10(t-1)/EMA_dolar_ccl_k=10(t-2)\"] = df_aux [\"EMA_dolar_ccl_k=10(t)\"].shift(1) / df_aux [\"EMA_dolar_ccl_k=10(t)\"].shift(2)\n",
    "    df_aux [\"EMA_dolar_ccl_k=40(t-1)/dolar_ccl(t-1)\"] = df_aux[\"EMA_dolar_ccl_k=40(t)\"].shift(1) / df_aux[\"dolar_ccl\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_ccl_k=30(t-1)/dolar_ccl(t-1)\"] = df_aux[\"EMA_dolar_ccl_k=30(t)\"].shift(1) / df_aux[\"dolar_ccl\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_ccl_k=15(t-1)/dolar_ccl(t-1)\"] = df_aux[\"EMA_dolar_ccl_k=15(t)\"].shift(1) / df_aux[\"dolar_ccl\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_ccl_k=20(t-1)/dolar_ccl(t-1)\"] = df_aux[\"EMA_dolar_ccl_k=20(t)\"].shift(1) / df_aux[\"dolar_ccl\"].shift(1)\n",
    "    df_aux [\"EMA_dolar_ccl_k=10(t-1)/dolar_ccl(t-1)\"] = df_aux[\"EMA_dolar_ccl_k=10(t)\"].shift(1) / df_aux[\"dolar_ccl\"].shift(1)\n",
    "\n",
    "\n",
    "    lista_de_df.append(df_aux)\n",
    "\n",
    "data = pd.concat(lista_de_df, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8Q_PKSiI6Jf"
   },
   "source": [
    "## Creación de Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos para cada acción/título las variables de entrada 'derivadas' a partir de los datos básicos:\n",
    "\n",
    "tiempo_inicial = time()   # Para medir el tiempo\n",
    "\n",
    "lista_de_df = []\n",
    "cantidad_dias = 2  # Definimos la cantidad de días hacia atrás que el algoritmo va a \"ver\" qué sucedió con los precios, dado un determinado día.\n",
    "\n",
    "for accion in data.groupby(['titulo']).groups.keys():\n",
    "  df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "\n",
    "\n",
    "  # VARIABLES RELACIONADAS ENTRE: Open - Close - High - Low : \n",
    "\n",
    "  df_aux [\"precio_medio\"] = (df_aux [\"low\"] + df_aux [\"high\"]) / 2\n",
    "\n",
    "  df_aux [\"open(t)/open(t-1)\"] = df_aux [\"open\"].shift(0) / df_aux [\"open\"].shift(1)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"open(t-\"+str(i+1)+\")/open(t-\"+str(i+2)+\")\"] = df_aux [\"open\"].shift(i+1) / df_aux [\"open\"].shift(i+2)\n",
    "\n",
    "  df_aux [\"close(t)/close(t-1)\"] = df_aux [\"close\"].shift(0) / df_aux [\"close\"].shift(1)\n",
    "  df_aux [\"close(t-1)/close(t-5)\"] = df_aux [\"close\"].shift(1) / df_aux [\"close\"].shift(5)\n",
    "  df_aux [\"close(t-1)/close(t-10)\"] = df_aux [\"close\"].shift(1) / df_aux [\"close\"].shift(10)\n",
    "  df_aux [\"close(t-1)/close(t-20)\"] = df_aux [\"close\"].shift(1) / df_aux [\"close\"].shift(20)\n",
    "  df_aux [\"close(t-1)/close(t-50)\"] = df_aux [\"close\"].shift(1) / df_aux [\"close\"].shift(50)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"close(t-\"+str(i+1)+\")/close(t-\"+str(i+2)+\")\"] = df_aux [\"close\"].shift(i+1) / df_aux [\"close\"].shift(i+2)\n",
    "\n",
    "  df_aux [\"high(t)/high(t-1)\"] = df_aux [\"high\"].shift(0) / df_aux [\"high\"].shift(1)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"high(t-\"+str(i+1)+\")/high(t-\"+str(i+2)+\")\"] = df_aux [\"high\"].shift(i+1) / df_aux [\"high\"].shift(i+2)\n",
    "\n",
    "  df_aux [\"low(t)/low(t-1)\"] = df_aux [\"low\"].shift(0) / df_aux [\"low\"].shift(1)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"low(t-\"+str(i+1)+\")/low(t-\"+str(i+2)+\")\"] = df_aux [\"low\"].shift(i+1) / df_aux [\"low\"].shift(i+2)\n",
    "\n",
    "  df_aux [\"volumen(t)/volumen(t-1)\"] = df_aux [\"volumen\"].shift(0) / df_aux [\"volumen\"].shift(1)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"volumen(t-\"+str(i+1)+\")/volumen(t-\"+str(i+2)+\")\"] = df_aux [\"volumen\"].shift(i+1) / df_aux [\"volumen\"].shift(i+2)\n",
    "\n",
    "\n",
    "  \n",
    "  df_aux [\"high(t)/open(t)\"] = (df_aux.high / df_aux.open) \n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"high(t-\"+str(i+1)+\")/open(t-\"+str(i+1)+\")\"] = df_aux [\"high(t)/open(t)\"].shift(i+1)\n",
    "\n",
    "  df_aux [\"open(t)/high(t-1)\"] = df_aux [\"open\"].shift(0) / df_aux [\"high\"].shift(1)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"open(t-\"+str(i+1)+\")/high(t-\"+str(i+2)+\")\"] = df_aux [\"open\"].shift(i+1) / df_aux [\"high\"].shift(i+2)\n",
    "    \n",
    "  df_aux [\"close(t)/open(t)\"] = (df_aux.close / df_aux.open) \n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"close(t-\"+str(i+1)+\")/open(t-\"+str(i+1)+\")\"] = df_aux [\"close(t)/open(t)\"].shift(i+1)\n",
    "\n",
    "  df_aux [\"open(t)/close(t-1)\"] = df_aux [\"open\"].shift(0) / df_aux [\"close\"].shift(1)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"open(t-\"+str(i+1)+\")/close(t-\"+str(i+2)+\")\"] = df_aux [\"open\"].shift(i+1) / df_aux [\"close\"].shift(i+2)\n",
    "\n",
    "  df_aux [\"low(t)/open(t)\"] = (df_aux.low / df_aux.open) \n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"low(t-\"+str(i+1)+\")/open(t-\"+str(i+1)+\")\"] = df_aux [\"low(t)/open(t)\"].shift(i+1)\n",
    "\n",
    "  df_aux [\"open(t)/low(t-1)\"] = df_aux [\"open\"].shift(0) / df_aux [\"low\"].shift(1)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"open(t-\"+str(i+1)+\")/low(t-\"+str(i+2)+\")\"] = df_aux [\"open\"].shift(i+1) / df_aux [\"low\"].shift(i+2)\n",
    "\n",
    "  df_aux [\"high(t)/low(t)\"] = (df_aux.high / df_aux.low) \n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"high(t-\"+str(i+1)+\")/low(t-\"+str(i+1)+\")\"] = df_aux [\"high(t)/low(t)\"].shift(i+1)\n",
    "\n",
    "  df_aux [\"high(t)/low(t-1)\"] = df_aux [\"high\"].shift(0) / df_aux [\"low\"].shift(1)\n",
    "  for i in range(5):\n",
    "    df_aux [\"high(t-\"+str(i+1)+\")/low(t-\"+str(i+2)+\")\"] = df_aux [\"high\"].shift(i+1) / df_aux [\"low\"].shift(i+2)\n",
    "\n",
    "  df_aux [\"high(t)/close(t)\"] = (df_aux.high / df_aux.close) \n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"high(t-\"+str(i+1)+\")/close(t-\"+str(i+1)+\")\"] = df_aux [\"high(t)/close(t)\"].shift(i+1)\n",
    "\n",
    "  df_aux [\"high(t)/close(t-1)\"] = df_aux [\"high\"].shift(0) / df_aux [\"close\"].shift(1)\n",
    "  for i in range(cantidad_dias):\n",
    "    df_aux [\"high(t-\"+str(i+1)+\")/close(t-\"+str(i+2)+\")\"] = df_aux [\"high\"].shift(i+1) / df_aux [\"close\"].shift(i+2)\n",
    "\n",
    "\n",
    "\n",
    "  # SMA (Media Móvil Simple): \n",
    "\n",
    "  # df_aux['SMA_close_k=5(t)'] = ta.trend.sma_indicator(df_aux.close,5)\n",
    "  # df_aux [\"SMA_close_k=5(t-1)/SMA_close_k=5(t-2)\"] = df_aux [\"SMA_close_k=5(t)\"].shift(1) / df_aux [\"SMA_close_k=5(t)\"].shift(2)\n",
    "  # df_aux [\"SMA_close_k=5(t-1)/close(t-1)\"] = df_aux [\"SMA_close_k=5(t)\"].shift(1) / df_aux [\"close\"].shift(1)\n",
    "  # df_aux [\"SMA_close_k=5(t-3)/close(t-1)\"] = df_aux [\"SMA_close_k=5(t)\"].shift(3) / df_aux [\"close\"].shift(1)\n",
    "  # df_aux [\"SMA_close_k=5(t-5)/close(t-1)\"] = df_aux [\"SMA_close_k=5(t)\"].shift(5) / df_aux [\"close\"].shift(1)\n",
    "\n",
    "  # df_aux['SMA_close_k=3(t)'] = ta.trend.sma_indicator(df_aux.close,3)\n",
    "  # df_aux [\"SMA_close_k=3(t-1)/SMA_close_k=3(t-2)\"] = df_aux [\"SMA_close_k=3(t)\"].shift(1) / df_aux [\"SMA_close_k=3(t)\"].shift(2)\n",
    "\n",
    "  # df_aux['SMA_close_k=10(t)'] = ta.trend.sma_indicator(df_aux.close,10)\n",
    "  # df_aux [\"SMA_close_k=10(t-1)/SMA_close_k=10(t-2)\"] = df_aux [\"SMA_close_k=10(t)\"].shift(1) / df_aux [\"SMA_close_k=10(t)\"].shift(2)\n",
    "\n",
    "\n",
    "  # EMA (Exponencial Móvil Simple): \n",
    "\n",
    "  df_aux['EMA_open_k=5(t)'] = ta.trend.ema_indicator(df_aux.open,5)\n",
    "  df_aux['EMA_open_k=6(t)'] = ta.trend.ema_indicator(df_aux.open,6)\n",
    "  df_aux['EMA_open_k=10(t)'] = ta.trend.ema_indicator(df_aux.open,10)\n",
    "  df_aux['EMA_open_k=20(t)'] = ta.trend.ema_indicator(df_aux.open,20)\n",
    "\n",
    "  df_aux['EMA_low_k=5(t)'] = ta.trend.ema_indicator(df_aux.low,5)\n",
    "  df_aux['EMA_low_k=10(t)'] = ta.trend.ema_indicator(df_aux.low,10)\n",
    "  df_aux['EMA_low_k=20(t)'] = ta.trend.ema_indicator(df_aux.low,20)\n",
    "  df_aux['EMA_low_k=3(t)'] = ta.trend.ema_indicator(df_aux.low,3)\n",
    "\n",
    "  df_aux['EMA_close_k=3(t)'] = ta.trend.ema_indicator(df_aux.close,3)\n",
    "  df_aux['EMA_close_k=10(t)'] = ta.trend.ema_indicator(df_aux.close,10)\n",
    "  df_aux['EMA_close_k=5(t)'] = ta.trend.ema_indicator(df_aux.close,5)\n",
    "  df_aux['EMA_close_k=2(t)'] = ta.trend.ema_indicator(df_aux.close,2)\n",
    "  df_aux['EMA_close_k=15(t)'] = ta.trend.ema_indicator(df_aux.close,15)\n",
    "  df_aux['EMA_close_k=20(t)'] = ta.trend.ema_indicator(df_aux.close,20)\n",
    "  df_aux['EMA_close_k=25(t)'] = ta.trend.ema_indicator(df_aux.close,25)\n",
    "  df_aux['EMA_close_k=30(t)'] = ta.trend.ema_indicator(df_aux.close,30)\n",
    "  df_aux['EMA_close_k=40(t)'] = ta.trend.ema_indicator(df_aux.close,40)\n",
    "  df_aux['EMA_close_k=50(t)'] = ta.trend.ema_indicator(df_aux.close,50)\n",
    "\n",
    "  df_aux['EMA_high_k=2(t)'] = ta.trend.ema_indicator(df_aux.high,2)\n",
    "  df_aux['EMA_high_k=3(t)'] = ta.trend.ema_indicator(df_aux.high,3)\n",
    "  df_aux['EMA_high_k=5(t)'] = ta.trend.ema_indicator(df_aux.high,5)\n",
    "  df_aux['EMA_high_k=10(t)'] = ta.trend.ema_indicator(df_aux.high,10)\n",
    "  df_aux['EMA_high_k=20(t)'] = ta.trend.ema_indicator(df_aux.high,20)\n",
    "\n",
    "\n",
    "  df_aux [\"EMA_close_k=5(t-1)/EMA_close_k=5(t-2)\"] = df_aux [\"EMA_close_k=5(t)\"].shift(1) / df_aux [\"EMA_close_k=5(t)\"].shift(2)\n",
    "  df_aux [\"EMA_close_k=5(t-1)/close(t-1)\"] = df_aux [\"EMA_close_k=5(t)\"].shift(1) / df_aux [\"close\"].shift(1)\n",
    "  df_aux [\"EMA_close_k=5(t-3)/close(t-1)\"] = df_aux [\"EMA_close_k=5(t)\"].shift(3) / df_aux [\"close\"].shift(1)\n",
    "  df_aux [\"EMA_close_k=5(t-5)/close(t-1)\"] = df_aux [\"EMA_close_k=5(t)\"].shift(5) / df_aux [\"close\"].shift(1)\n",
    "  df_aux [\"EMA_close_k=3(t-1)/EMA_close_k=3(t-2)\"] = df_aux [\"EMA_close_k=3(t)\"].shift(1) / df_aux [\"EMA_close_k=3(t)\"].shift(2)\n",
    "  df_aux [\"EMA_close_k=10(t-1)/EMA_close_k=10(t-2)\"] = df_aux [\"EMA_close_k=10(t)\"].shift(1) / df_aux [\"EMA_close_k=10(t)\"].shift(2)\n",
    "  df_aux [\"EMA_close_k=40(t-1)/precio_medio(t-1)\"] = df_aux[\"EMA_close_k=40(t)\"].shift(1) / df_aux[\"precio_medio\"].shift(1)\n",
    "  df_aux [\"EMA_close_k=30(t-1)/precio_medio(t-1)\"] = df_aux[\"EMA_close_k=30(t)\"].shift(1) / df_aux[\"precio_medio\"].shift(1)\n",
    "  df_aux [\"EMA_close_k=15(t-1)/precio_medio(t-1)\"] = df_aux[\"EMA_close_k=15(t)\"].shift(1) / df_aux[\"precio_medio\"].shift(1)\n",
    "  df_aux [\"EMA_close_k=20(t-1)/precio_medio(t-1)\"] = df_aux[\"EMA_close_k=20(t)\"].shift(1) / df_aux[\"precio_medio\"].shift(1)\n",
    "  df_aux [\"EMA_close_k=10(t-1)/precio_medio(t-1)\"] = df_aux[\"EMA_close_k=10(t)\"].shift(1) / df_aux[\"precio_medio\"].shift(1)\n",
    "  df_aux [\"EMA_close_k=20(t-1)/EMA_close_k=5(t-1)\"] = df_aux[\"EMA_close_k=20(t)\"].shift(1) / df_aux[\"EMA_close_k=5(t)\"].shift(1)\n",
    "  df_aux [\"(EMA_close_k=20(t-1)-EMA_close_k=5(t-1))/precio_medio(t-1)\"] = (df_aux[\"EMA_close_k=20(t)\"].shift(1) - df_aux[\"EMA_close_k=5(t)\"].shift(1)) / df_aux[\"precio_medio\"].shift(1)\n",
    "  df_aux [\"(EMA_close_k=20(t-1)-precio_medio(t-1)))/precio_medio(t-1)\"] = (df_aux[\"EMA_close_k=20(t)\"].shift(1) - df_aux[\"precio_medio\"].shift(1)) / df_aux[\"precio_medio\"].shift(1)\n",
    "\n",
    "  df_aux[\"(EMA_high_k=3(t-1)-EMA_close_k=3(t-1))/precio_medio(t-1)\"] = (df_aux[\"EMA_high_k=3(t)\"].shift(1) - df_aux[\"EMA_close_k=3(t)\"].shift(1)) / df_aux[\"precio_medio\"].shift(1)\n",
    "  df_aux[\"(EMA_close_k=3(t-1)-EMA_low_k=3(t-1))/precio_medio(t-1)\"] = (df_aux[\"EMA_close_k=3(t)\"].shift(1) - df_aux[\"EMA_low_k=3(t)\"].shift(1)) / df_aux[\"precio_medio\"].shift(1)\n",
    "  df_aux[\"(EMA_high_k=5(t-1)-EMA_low_k=5(t-1))/precio_medio(t-1)\"] = (df_aux[\"EMA_high_k=5(t)\"].shift(1) - df_aux[\"EMA_low_k=5(t)\"].shift(1)) / df_aux[\"precio_medio\"].shift(1)\n",
    "\n",
    "\n",
    "\n",
    "  # Creación de variables de tendencia:  \n",
    "  for i in range (1,6):\n",
    "    df_aux [\"movimiento_descendente(t-\"+str(i)+\")\"] = np.where( df_aux [\"precio_medio\"].shift(i) < df_aux [\"precio_medio\"].shift(i+1), 1, 0 )\n",
    "    df_aux [\"movimiento_ascendente(t-\"+str(i)+\")\"] = np.where( df_aux [\"precio_medio\"].shift(i) > df_aux [\"precio_medio\"].shift(i+1), 1, 0 )\n",
    "\n",
    "\n",
    "  df_aux [\"tendencia_descendente_pequeña\"] = np.where( sum([df_aux[\"movimiento_descendente(t-1)\"], df_aux[\"movimiento_descendente(t-2)\"]]) == 2, 1, 0 )\n",
    "  df_aux [\"tendencia_descendente_mediana\"] = np.where( sum([df_aux[\"movimiento_descendente(t-1)\"], df_aux[\"movimiento_descendente(t-2)\"],\n",
    "                                                        df_aux[\"movimiento_descendente(t-3)\"]]) == 3, 1, 0 )\n",
    "  df_aux [\"tendencia_descendente_mediana_intermedia\"] = np.where( (sum([df_aux[\"movimiento_descendente(t-1)\"], df_aux[\"movimiento_descendente(t-2)\"],\n",
    "                                                                   df_aux[\"movimiento_descendente(t-3)\"], df_aux[\"movimiento_descendente(t-4)\"]]) >= 3) &\n",
    "                                                                  (df_aux[\"movimiento_descendente(t-1)\"] == 1), 1, 0 )\n",
    "  df_aux [\"tendencia_descendente_grande\"] = np.where( (sum([df_aux[\"movimiento_descendente(t-1)\"], df_aux[\"movimiento_descendente(t-2)\"],\n",
    "                                                        df_aux[\"movimiento_descendente(t-3)\"], df_aux[\"movimiento_descendente(t-4)\"],\n",
    "                                                        df_aux[\"movimiento_descendente(t-5)\"]]) >= 4) & (df_aux[\"movimiento_descendente(t-1)\"] == 1), 1, 0 )\n",
    "\n",
    "  df_aux [\"tendencia_ascendente_pequeña\"] = np.where( sum([df_aux[\"movimiento_ascendente(t-1)\"], df_aux[\"movimiento_ascendente(t-2)\"]]) == 2, 1, 0 )\n",
    "  df_aux [\"tendencia_ascendente_mediana\"] = np.where( sum([df_aux[\"movimiento_ascendente(t-1)\"], df_aux[\"movimiento_ascendente(t-2)\"],\n",
    "                                                        df_aux[\"movimiento_ascendente(t-3)\"]]) == 3, 1, 0 )\n",
    "  df_aux [\"tendencia_ascendente_mediana_intermedia\"] = np.where( (sum([df_aux[\"movimiento_ascendente(t-1)\"], df_aux[\"movimiento_ascendente(t-2)\"],\n",
    "                                                                   df_aux[\"movimiento_ascendente(t-3)\"], df_aux[\"movimiento_ascendente(t-4)\"]]) >= 3) &\n",
    "                                                                  (df_aux[\"movimiento_ascendente(t-1)\"] == 1), 1, 0 )\n",
    "  df_aux [\"tendencia_ascendente_grande\"] = np.where( (sum([df_aux[\"movimiento_ascendente(t-1)\"], df_aux[\"movimiento_ascendente(t-2)\"],\n",
    "                                                        df_aux[\"movimiento_ascendente(t-3)\"], df_aux[\"movimiento_ascendente(t-4)\"],\n",
    "                                                        df_aux[\"movimiento_ascendente(t-5)\"]]) >= 4) & (df_aux[\"movimiento_ascendente(t-1)\"] == 1), 1, 0 )\n",
    "\n",
    "\n",
    "\n",
    "  # Creación de Valles y Cimas:\n",
    "\n",
    "  # Se denomina Valle cuando la cotización disminuye hasta cierto momento donde empieza a subir.\n",
    "  df_aux [\"valle_tipo_1\"] = np.where( (sum([df_aux [\"movimiento_ascendente(t-1)\"] , df_aux[\"movimiento_ascendente(t-2)\"]]) == 2) &\n",
    "                                      (sum([df_aux [\"movimiento_descendente(t-3)\"] , df_aux[\"movimiento_descendente(t-4)\"]]) == 2) , 1, 0 ) \n",
    "  \n",
    "  # Se denomina Cima cuando la cotización aumenta hasta cierto momento donde empieza a caer.\n",
    "  df_aux [\"cima_tipo_1\"] = np.where( (sum([df_aux [\"movimiento_descendente(t-1)\"] , df_aux[\"movimiento_descendente(t-2)\"]]) == 2) &\n",
    "                                     (sum([df_aux [\"movimiento_ascendente(t-3)\"] , df_aux[\"movimiento_ascendente(t-4)\"]]) == 2) , 1, 0 ) \n",
    "\n",
    "\n",
    "  df_aux [\"valle_tipo_2\"] = np.where( (sum([df_aux [\"movimiento_ascendente(t-1)\"] , df_aux[\"movimiento_ascendente(t-2)\"]]) == 2) &\n",
    "                                      (sum([df_aux [\"movimiento_descendente(t-3)\"] , df_aux[\"movimiento_descendente(t-4)\"],\n",
    "                                          df_aux[\"movimiento_descendente(t-5)\"]]) >= 2),  1, 0 ) \n",
    "\n",
    "  df_aux [\"cima_tipo_2\"] = np.where( (sum([df_aux [\"movimiento_descendente(t-1)\"] , df_aux[\"movimiento_descendente(t-2)\"]]) == 2) &\n",
    "                                     (sum([df_aux [\"movimiento_ascendente(t-3)\"] , df_aux[\"movimiento_ascendente(t-4)\"],\n",
    "                                          df_aux[\"movimiento_ascendente(t-5)\"]]) >= 2) , 1, 0 ) \n",
    "    \n",
    "\n",
    "  # Creación de variables a MEDIANO / LARGO plazo:\n",
    "  añadir_variable_maximo_de_high_sobre_open(df_aux,5)\n",
    "  añadir_variable_maximo_de_high_sobre_open(df_aux,10)\n",
    "  añadir_variable_maximo_de_high_sobre_open(df_aux,15)\n",
    "  añadir_variable_maximo_de_high_sobre_open(df_aux,20)\n",
    "  añadir_variable_maximo_de_high_sobre_open(df_aux,30)\n",
    "  añadir_variable_maximo_de_high_sobre_open(df_aux,40)\n",
    "  añadir_variable_maximo_de_high_sobre_open(df_aux,60)\n",
    "\n",
    "  añadir_variable_minimo_de_high_sobre_open(df_aux,5)\n",
    "  añadir_variable_minimo_de_high_sobre_open(df_aux,10)\n",
    "  añadir_variable_minimo_de_high_sobre_open(df_aux,15)\n",
    "  añadir_variable_minimo_de_high_sobre_open(df_aux,20)\n",
    "  añadir_variable_minimo_de_high_sobre_open(df_aux,25)\n",
    "  añadir_variable_minimo_de_high_sobre_open(df_aux,30)\n",
    "  añadir_variable_minimo_de_high_sobre_open(df_aux,40)\n",
    "  añadir_variable_minimo_de_high_sobre_open(df_aux,60)\n",
    "\n",
    "  añadir_variable_minimo_de_low_sobre_open(df_aux,5)\n",
    "  añadir_variable_minimo_de_low_sobre_open(df_aux,10)\n",
    "  añadir_variable_minimo_de_low_sobre_open(df_aux,15)\n",
    "  añadir_variable_minimo_de_low_sobre_open(df_aux,20)\n",
    "  añadir_variable_minimo_de_low_sobre_open(df_aux,25)\n",
    "  añadir_variable_minimo_de_low_sobre_open(df_aux,30)\n",
    "  añadir_variable_minimo_de_low_sobre_open(df_aux,40)\n",
    "  añadir_variable_minimo_de_low_sobre_open(df_aux,60)\n",
    "\n",
    "  añadir_variable_close_mas_X_dias_sobre_open(df_aux,10)\n",
    "  añadir_variable_close_mas_X_dias_sobre_open(df_aux,15)\n",
    "  añadir_variable_close_mas_X_dias_sobre_open(df_aux,25)\n",
    "\n",
    "  lista_de_df.append(df_aux)\n",
    "\n",
    "data = pd.concat(lista_de_df, axis=0)\n",
    "\n",
    "\n",
    "tiempo_final = time()  # Para medir el tiempo\n",
    "tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "print(\"\")\n",
    "print ('El tiempo de ejecución fue:',tiempo_ejecucion, 'segundos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos más features:\n",
    "\n",
    "data[\"variacion_close_(t-2)/variacion_dolar_blue_(t-2)\"] = data[\"close(t-1)/close(t-2)\"] / data[\"dolar_blue(t-1)/dolar_blue(t-2)\"]\n",
    "data[\"variacion_close_(t-5)/variacion_dolar_blue_(t-5)\"] = data[\"close(t-1)/close(t-5)\"] / data[\"dolar_blue(t-1)/dolar_blue(t-5)\"]\n",
    "data[\"variacion_close_(t-10)/variacion_dolar_blue_(t-10)\"] = data[\"close(t-1)/close(t-10)\"] / data[\"dolar_blue(t-1)/dolar_blue(t-10)\"]\n",
    "data[\"variacion_close_(t-20)/variacion_dolar_blue_(t-20)\"] = data[\"close(t-1)/close(t-20)\"] / data[\"dolar_blue(t-1)/dolar_blue(t-20)\"]\n",
    "data[\"variacion_close_(t-50)/variacion_dolar_blue_(t-50)\"] = data[\"close(t-1)/close(t-50)\"] / data[\"dolar_blue(t-1)/dolar_blue(t-50)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de variables nominales binarias (0 ó 1) a partir de un valor umbral:\n",
    "\n",
    "for umbral in (1.01 , 1.015, 1.018, 1.02 , 1.025, 1.03 , 1.035, 1.04):\n",
    "  añadir_variable_nominal_binaria_mayor_que (data,\"high(t)/open(t)\",umbral)\n",
    "  for i in range(1):\n",
    "        lista_de_df = []\n",
    "        for accion in data.groupby(['titulo']).groups.keys():\n",
    "            df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "            df_aux [\"umbral_=_\"+str(umbral)+\"_high(t-\"+str(i+1)+\")/open(t-\"+str(i+1)+\")\"] = df_aux [\"umbral_=_\"+str(umbral)+\"_high(t)/open(t)\"].shift(i+1)\n",
    "            lista_de_df.append(df_aux)\n",
    "        data = pd.concat(lista_de_df, axis=0)\n",
    "\n",
    "umbral = 1.015\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"close(t)/open(t)\",umbral)\n",
    "for i in range(1):\n",
    "    lista_de_df = []\n",
    "    for accion in data.groupby(['titulo']).groups.keys():\n",
    "        df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "        df_aux [\"umbral_=_\"+str(umbral)+\"_close(t-\"+str(i+1)+\")/open(t-\"+str(i+1)+\")\"] = df_aux [\"umbral_=_\"+str(umbral)+\"_close(t)/open(t)\"].shift(i+1)\n",
    "        lista_de_df.append(df_aux)\n",
    "    data = pd.concat(lista_de_df, axis=0)\n",
    "\n",
    "umbral = 1.02\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"close(t)/open(t)\",umbral)\n",
    "for i in range(3):\n",
    "    lista_de_df = []\n",
    "    for accion in data.groupby(['titulo']).groups.keys():\n",
    "        df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "        df_aux [\"umbral_=_\"+str(umbral)+\"_close(t-\"+str(i+1)+\")/open(t-\"+str(i+1)+\")\"] = df_aux [\"umbral_=_\"+str(umbral)+\"_close(t)/open(t)\"].shift(i+1)\n",
    "        lista_de_df.append(df_aux)\n",
    "    data = pd.concat(lista_de_df, axis=0)\n",
    "    \n",
    "\n",
    "umbral = 1.04\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_10_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_5_dias/open(t)\",umbral)\n",
    "\n",
    "umbral = 1.05\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_5_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_10_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_15_dias/open(t)\",umbral)\n",
    "\n",
    "umbral = 1.06\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"close(t+10)/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"close(t+15)/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_10_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_15_dias/open(t)\",umbral)\n",
    "\n",
    "umbral = 1.08\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_15_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_10_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_5_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"close(t+10)/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"close(t+15)/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"close(t+25)/open(t)\",umbral)\n",
    "\n",
    "umbral = 1.1\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_20_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_15_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_10_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_5_dias/open(t)\",umbral)\n",
    "\n",
    "umbral = 1.12\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_15_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_10_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_5_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_20_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_40_dias/open(t)\",umbral)\n",
    "\n",
    "umbral = 1.15\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_20_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_30_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_40_dias/open(t)\",umbral)\n",
    "\n",
    "umbral = 1.2\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_20_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_30_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_40_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_60_dias/open(t)\",umbral)\n",
    "\n",
    "umbral = 1.3\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_15_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_40_dias/open(t)\",umbral)\n",
    "añadir_variable_nominal_binaria_mayor_que (data,\"maximo_de_high_en_proximos_60_dias/open(t)\",umbral)\n",
    "\n",
    "\n",
    "umbral = 0.95\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_10_dias/open(t)\",umbral )\n",
    "\n",
    "umbral = 0.92\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_15_dias/open(t)\",umbral )\n",
    "\n",
    "umbral = 0.90\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_20_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_25_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_30_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_20_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_25_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_30_dias/open(t)\",umbral )\n",
    "\n",
    "umbral = 0.88\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_20_dias/open(t)\",umbral )\n",
    "\n",
    "umbral = 0.85\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_20_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_25_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_30_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_20_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_25_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_30_dias/open(t)\",umbral )\n",
    "\n",
    "umbral = 0.80\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_20_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_25_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_30_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_40_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_60_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_5_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_10_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_20_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_25_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_30_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_40_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_low_en_proximos_60_dias/open(t)\",umbral )\n",
    "\n",
    "umbral = 0.75\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_20_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_30_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_40_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_60_dias/open(t)\",umbral )\n",
    "\n",
    "umbral = 0.70\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_15_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_20_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_30_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_40_dias/open(t)\",umbral )\n",
    "añadir_variable_nominal_binaria_menor_que (data, \"minimo_de_high_en_proximos_60_dias/open(t)\",umbral )\n",
    "\n",
    "\n",
    "# Construimos variables umbrales \"combinadas\", que surgen de que se cumplan 2 condiciones simultáneas:\n",
    "\n",
    "variable_target_1 = \"umbral_=_0.9_minimo_de_low_en_proximos_10_dias/open(t)\"\n",
    "variable_target_2 = \"umbral_=_1.06_maximo_de_high_en_proximos_15_dias/open(t)\"\n",
    "data[variable_target_1 + \"_&_∼_\" + variable_target_2]  = np.where((data[variable_target_1] == 1) & (data[variable_target_2] == 0), 1, 0)\n",
    "\n",
    "variable_target_1 = \"umbral_=_0.9_minimo_de_low_en_proximos_10_dias/open(t)\"\n",
    "variable_target_2 = \"umbral_=_1.06_maximo_de_high_en_proximos_10_dias/open(t)\"\n",
    "data[variable_target_1 + \"_&_∼_\" + variable_target_2]  = np.where((data[variable_target_1] == 1) & (data[variable_target_2] == 0), 1, 0)\n",
    "\n",
    "variable_target_1 = \"umbral_=_0.9_minimo_de_low_en_proximos_10_dias/open(t)\"\n",
    "variable_target_2 = \"umbral_=_1.05_maximo_de_high_en_proximos_5_dias/open(t)\"\n",
    "data[variable_target_1 + \"_&_∼_\" + variable_target_2]  = np.where((data[variable_target_1] == 1) & (data[variable_target_2] == 0), 1, 0)\n",
    "\n",
    "variable_target_1 = \"umbral_=_0.92_minimo_de_low_en_proximos_10_dias/open(t)\"\n",
    "variable_target_2 = \"umbral_=_1.06_maximo_de_high_en_proximos_15_dias/open(t)\"\n",
    "data[variable_target_1 + \"_&_∼_\" + variable_target_2]  = np.where((data[variable_target_1] == 1) & (data[variable_target_2] == 0), 1, 0)\n",
    "\n",
    "variable_target_1 = \"umbral_=_0.92_minimo_de_low_en_proximos_10_dias/open(t)\"\n",
    "variable_target_2 = \"umbral_=_1.06_maximo_de_high_en_proximos_10_dias/open(t)\"\n",
    "data[variable_target_1 + \"_&_∼_\" + variable_target_2]  = np.where((data[variable_target_1] == 1) & (data[variable_target_2] == 0), 1, 0)\n",
    "\n",
    "variable_target_1 = \"umbral_=_0.92_minimo_de_low_en_proximos_10_dias/open(t)\"\n",
    "variable_target_2 = \"umbral_=_1.05_maximo_de_high_en_proximos_5_dias/open(t)\"\n",
    "data[variable_target_1 + \"_&_∼_\" + variable_target_2]  = np.where((data[variable_target_1] == 1) & (data[variable_target_2] == 0), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "odXY_QoUUJyH"
   },
   "outputs": [],
   "source": [
    "# Creación de variables nominales binarias (0 ó 1) para cada título a través de One Hot Encoding:\n",
    "data = aplicar_one_hot_encoding_a_un_DataFrame (data, \"titulo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "5Fcg_n8oN3oW"
   },
   "outputs": [],
   "source": [
    "# Creación de variables nominales binarias (0 ó 1) a partir de la información que obtuvimos de los Baselines:\n",
    "\n",
    "umbral = 1.1\n",
    "lista_de_df = []\n",
    "\n",
    "for accion in data.groupby(['titulo']).groups.keys():\n",
    "  df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "  df_aux [\"prediccion_del_baseline\"] = np.where( df_aux[\"high\"].shift(1) / df_aux[\"low\"].shift(1) >= umbral, 1, 0)\n",
    "  lista_de_df.append (df_aux[\"prediccion_del_baseline\"])\n",
    "\n",
    "data[\"umbral_=_1.1_high(t-1)/low(t-1)\"] = pd.concat(lista_de_df, axis=0) \n",
    "\n",
    "umbral = 1.13\n",
    "lista_de_df = []\n",
    "\n",
    "for accion in data.groupby(['titulo']).groups.keys():\n",
    "  df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "  df_aux [\"prediccion_del_baseline\"] = np.where( df_aux[\"high\"].shift(1) / df_aux[\"low\"].shift(1) >= umbral, 1, 0)\n",
    "  lista_de_df.append (df_aux[\"prediccion_del_baseline\"])\n",
    "\n",
    "data[\"umbral_=_1.13_high(t-1)/low(t-1)\"] = pd.concat(lista_de_df, axis=0) \n",
    "\n",
    "umbral = 1.15\n",
    "lista_de_df = []\n",
    "\n",
    "for accion in data.groupby(['titulo']).groups.keys():\n",
    "  df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "  df_aux [\"prediccion_del_baseline\"] = np.where( df_aux[\"high\"].shift(1) / df_aux[\"low\"].shift(1) >= umbral, 1, 0)\n",
    "  lista_de_df.append (df_aux[\"prediccion_del_baseline\"])\n",
    "\n",
    "data[\"umbral_=_1.15_high(t-1)/low(t-1)\"] = pd.concat(lista_de_df, axis=0) \n",
    "\n",
    "umbral = 1.28\n",
    "lista_de_df = []\n",
    "\n",
    "for accion in data.groupby(['titulo']).groups.keys():\n",
    "  df_aux = data.groupby(['titulo']).get_group(accion).sort_values(by=\"fecha\") \n",
    "  df_aux [\"prediccion_del_baseline\"] = np.where( df_aux[\"high\"].shift(1) / df_aux[\"low\"].shift(1) >= umbral, 1, 0)\n",
    "  lista_de_df.append (df_aux[\"prediccion_del_baseline\"])\n",
    "\n",
    "data[\"umbral_=_1.28_high(t-1)/low(t-1)\"] = pd.concat(lista_de_df, axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos todos los indicadores técnicos que están incluidos en la librería 'ta' de Python:\n",
    "data = agregar_todos_los_indicadores_tecnicos_de_la_libreria_ta(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "MN930cvOt41O"
   },
   "outputs": [],
   "source": [
    "# Creamos features simples para identificar las tendencias en la cotización:\n",
    "data[\"TA_LIB_trend_psar_down_simplificado\"] = np.where( data[\"TA_LIB_trend_psar_down\"]!=0 , 1, 0 )  #Indica con un 1 cuando se está en tendencia bajista, y 0 en caso contrario.\n",
    "data[\"TA_LIB_trend_psar_up_simplificado\"] = np.where( data[\"TA_LIB_trend_psar_up\"]!=0 , 1, 0 )   #Indica con un 1 cuando se está en tendencia alcista, y 0 en caso contrario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "E1u3FZgG4JTX"
   },
   "outputs": [],
   "source": [
    "# Ordenamos el DataFrame por fecha:\n",
    "data = data.sort_values( by=[\"fecha\"], ascending = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_5ND9qY3X76"
   },
   "source": [
    "## Catálogo de los Tipos de Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "oOop6fJ6pThD"
   },
   "outputs": [],
   "source": [
    "# Catalogamos las variables del DataFrame en 4 categorías:\n",
    "#  - Variables Target Intradiarias  (son variables Dependientes)\n",
    "#  - Variables Target de Largo Plazo  (son variables Dependientes)\n",
    "#  - Variables NO utilizadas para entrenar (los modelos NO las tienen en cuenta en ningún aspecto)\n",
    "#  - Variables Independientes (serán todas las demás variables que no estén especificadas en las categorías anteriores y se catalogarán automáticamente)\n",
    "\n",
    "variables_no_utilizadas_para_entrenar = {\"titulo\",\"fecha_IOL\",\"open\",\"close\",\"high\",\"low\",\"volumen\",\"fecha\", \"precio_medio\",\n",
    "                                         \"dolar_blue\", \"dolar_ccl\", \"dolar_blue_compra\", \"dolar_blue_venta\", \"dolar_ccl_compra\", \"dolar_ccl_venta\",\n",
    "                                         \"open_pesos\", \"close_pesos\", \"low_pesos\", \"high_pesos\",\n",
    "                                        'SMA_close_k=5(t)', 'EMA_close_k=5(t)', 'EMA_close_k=10(t)', 'EMA_close_k=20(t)',\n",
    "                                        'EMA_close_k=50(t)', 'EMA_close_k=100(t)', 'EMA_close_k=30(t)', 'EMA_close_k=15(t)',\n",
    "                                        'EMA_high_k=5(t)', 'EMA_high_k=10(t)', 'EMA_high_k=20(t)', 'EMA_high_k=50(t)',\n",
    "                                        \"SMA_close_k=3(t)\",\"SMA_close_k=5(t)\",\"SMA_close_k=10(t)\",\n",
    "                                        \"EMA_close_k=3(t)\", \"subio_o_bajo_(t)\",\"es_o_no_canal_paralelo_(t-1)\", \"año\",\"dia\",\"mes\",\n",
    "                                        'SMA_close_k=5(t)/SMA_close_k=5(t-1)', 'EMA_close_k=5(t)/EMA_close_k=5(t-1)',\n",
    "                                        'EMA_close_k=10(t)/EMA_close_k=10(t-1)','EMA_close_k=20(t)/EMA_close_k=20(t-1)', \n",
    "                                        'EMA_high_k=5(t)/EMA_high_k=5(t-1)', 'EMA_high_k=10(t)/EMA_high_k=10(t-1)',\n",
    "                                        'EMA_high_k=20(t)/EMA_high_k=20(t-1)', 'EMA_high_k=50(t)/EMA_high_k=50(t-1)',\n",
    "                                        'EMA_close_k=5(t)/EMA_close_k=10(t)', 'EMA_close_k=10(t)/EMA_close_k=20(t)',\n",
    "                                        'EMA_close_k=20(t)/EMA_close_k=50(t)', 'EMA_high_k=5(t)/EMA_high_k=10(t)',\n",
    "                                        'EMA_high_k=10(t)/EMA_high_k=20(t)', 'EMA_high_k=20(t)/EMA_high_k=50(t)',\n",
    "                                        'EMA_close_k=50(t)/EMA_close_k=50(t-1)', \"(high(t)+low(t)/2) / EMA_close_k=30(t)\",\n",
    "                                        '(high(t)+low(t)/2) / EMA_close_k=100(t)', \"(high(t)+low(t)/2) / EMA_close_k=15(t)\",\n",
    "                                        '(high(t)+low(t)/2) / EMA_close_k=100(t)', \"(high(t)+low(t)/2) / EMA_close_k=30(t)\",\n",
    "                                        '(high(t)+low(t)/2) / EMA_close_k=15(t)', \"EMA_close_k=40(t)\", \"EMA_high_k=3(t)\",\n",
    "                                         \"EMA_high_k=5(t)\", \"EMA_high_k=10(t)\", \"EMA_high_k=2(t)\", \"EMA_close_k=2(t)\", \"EMA_low_k=5(t)\",\n",
    "                                         \"EMA_open_k=5(t)\", \"EMA_open_k=6(t)\", \"EMA_close_k=25(t)\", \"EMA_low_k=10(t)\", \"EMA_low_k=3(t)\",\n",
    "                                         \"EMA_open_k=10(t)\", \"EMA_open_k=20(t)\", \"EMA_low_k=20(t)\", \"EMA_high_k=20(t)\",\n",
    "                                         \"EMA_dolar_blue_k=20(t)\", \"EMA_dolar_ccl_k=20(t)\", \"EMA_dolar_blue_k=2(t)\",\n",
    "                                         \"EMA_dolar_ccl_k=3(t)\", \"EMA_dolar_blue_k=3(t)\", \"EMA_dolar_ccl_k=2(t)\",\n",
    "                                         \"EMA_dolar_ccl_k=10(t)\", \"EMA_dolar_blue_k=10(t)\", \"EMA_dolar_blue_k=40(t)\", \"EMA_dolar_ccl_k=40(t)\",\n",
    "                                         \"EMA_dolar_blue_k=50(t)\", \"EMA_dolar_ccl_k=50(t)\", \"EMA_dolar_blue_k=5(t)\", \"EMA_dolar_ccl_k=5(t)\",\n",
    "                                         \"EMA_dolar_ccl_k=25(t)\", \"EMA_dolar_blue_k=25(t)\", \"EMA_dolar_ccl_k=15(t)\", \"EMA_dolar_blue_k=15(t)\",\n",
    "                                         \"EMA_dolar_blue_k=30(t)\", \"EMA_dolar_ccl_k=30(t)\"\n",
    "                                         }\n",
    "\n",
    "variables_target_intradiarias = {\"close(t)/close(t-1)\",\"high(t)/high(t-1)\",\"low(t)/low(t-1)\",\"volumen(t)/volumen(t-1)\",\n",
    "                                'high(t)/open(t)', 'close(t)/open(t)', 'low(t)/open(t)', 'high(t)/low(t)', 'high(t)/low(t-1)',\n",
    "                                'high(t)/close(t)', 'high(t)/close(t-1)', \"umbral_=_1.03_high(t)/open(t)\", \"umbral_=_1.02_close(t)/open(t)\",\n",
    "                                'umbral_=_1.015_close(t)/open(t)', \"umbral_=_1.013_close(t)/open(t)\", \"umbral_=_1.01_high(t)/open(t)\",\n",
    "                                 \"umbral_=_1.015_high(t)/open(t)\", \"umbral_=_1.02_high(t)/open(t)\", \"umbral_=_1.025_high(t)/open(t)\",\n",
    "                                 \"umbral_=_1.035_high(t)/open(t)\", \"umbral_=_1.04_high(t)/open(t)\", \"umbral_=_1.018_high(t)/open(t)\"                            \n",
    "                                 }\n",
    "\n",
    "variables_target_de_largo_plazo = {\"low(t+3)/open(t)\", \"minimo_de_low_en_proximos_3_dias/open(t)\",\n",
    "                                  \"maximo_de_high_en_proximos_20_dias/open(t)\", \"umbral_=_1.1_maximo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                  \"maximo_de_high_en_proximos_40_dias/open(t)\",\"maximo_de_high_en_proximos_5_dias/open(t)\",\n",
    "                                  \"maximo_de_high_en_proximos_10_dias/open(t)\", \"umbral_=_1.08_maximo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                  \"umbral_=_1.1_maximo_de_high_en_proximos_5_dias/open(t)\", \"umbral_=_1.08_maximo_de_high_en_proximos_5_dias/open(t)\",\n",
    "                                  \"umbral_=_1.12_maximo_de_high_en_proximos_5_dias/open(t)\", \"maximo_de_high_en_proximos_15_dias/open(t)\",\n",
    "                                  \"umbral_=_1.12_maximo_de_high_en_proximos_10_dias/open(t)\", \"umbral_=_1.1_maximo_de_high_en_proximos_15_dias/open(t)\",\n",
    "                                  \"umbral_=_1.1_maximo_de_high_en_proximos_25_dias/open(t)\", \"umbral_=_1.12_maximo_de_high_en_proximos_15_dias/open(t)\",\n",
    "                                  \"umbral_=_1.08_maximo_de_high_en_proximos_15_dias/open(t)\", \"umbral_=_1.06_close(t+15)/open(t)\", \n",
    "                                  \"umbral_=_1.08_close(t+15)/open(t)\", \"umbral_=_1.06_close(t+10)/open(t)\", \"umbral_=_1.08_close(t+10)/open(t)\",\n",
    "                                  \"umbral_=_1.08_close(t+25)/open(t)\", \"close(t+45)/open(t)\", \"close(t+25)/open(t)\", \"close(t+15)/open(t)\",\n",
    "                                  \"close(t+10)/open(t)\", \"close(t+5)/open(t)\", \"umbral_=_1.06_maximo_de_high_en_proximos_15_dias/open(t)\",\n",
    "                                  \"umbral_=_1.06_maximo_de_high_en_proximos_10_dias/open(t)\", \"umbral_=_1.05_maximo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                  \"umbral_=_1.05_maximo_de_high_en_proximos_15_dias/open(t)\", \"umbral_=_1.04_maximo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_1.1_maximo_de_high_en_proximos_20_dias/open(t)\", \"umbral_=_1.04_maximo_de_high_en_proximos_5_dias/open(t)\",\n",
    "                                   \"umbral_=_1.05_maximo_de_high_en_proximos_5_dias/open(t)\", \"maximo_de_high_en_proximos_30_dias/open(t)\",\n",
    "                                   \"maximo_de_high_en_proximos_40_dias/open(t)\", \"maximo_de_high_en_proximos_60_dias/open(t)\",\n",
    "                                   \"umbral_=_1.3_maximo_de_high_en_proximos_60_dias/open(t)\", \"umbral_=_1.2_maximo_de_high_en_proximos_60_dias/open(t)\",\n",
    "                                   \"umbral_=_1.15_maximo_de_high_en_proximos_20_dias/open(t)\", \"umbral_=_1.15_maximo_de_high_en_proximos_40_dias/open(t)\",\n",
    "                                   \"umbral_=_1.3_maximo_de_high_en_proximos_40_dias/open(t)\", \"umbral_=_1.12_maximo_de_high_en_proximos_40_dias/open(t)\",\n",
    "                                   \"umbral_=_1.12_maximo_de_high_en_proximos_20_dias/open(t)\", \"umbral_=_1.2_maximo_de_high_en_proximos_30_dias/open(t)\",\n",
    "                                   \"umbral_=_1.2_maximo_de_high_en_proximos_40_dias/open(t)\", \"umbral_=_1.15_maximo_de_high_en_proximos_30_dias/open(t)\",\n",
    "                                   \"umbral_=_1.2_maximo_de_high_en_proximos_20_dias/open(t)\", \"minimo_de_high_en_proximos_60_dias/open(t)\",\n",
    "                                   \"minimo_de_high_en_proximos_30_dias/open(t)\", \"minimo_de_high_en_proximos_20_dias/open(t)\",\n",
    "                                   \"minimo_de_high_en_proximos_10_dias/open(t)\", \"minimo_de_high_en_proximos_5_dias/open(t)\",\n",
    "                                   \"minimo_de_high_en_proximos_15_dias/open(t)\", \"umbral_=_0.75_minimo_de_high_en_proximos_15_dias/open(t)\",\n",
    "                                   \"umbral_=_0.75_minimo_de_high_en_proximos_20_dias/open(t)\", \"umbral_=_0.75_minimo_de_high_en_proximos_30_dias/open(t)\",\n",
    "                                   \"umbral_=_0.75_minimo_de_high_en_proximos_40_dias/open(t)\", \"umbral_=_0.75_minimo_de_high_en_proximos_60_dias/open(t)\",\n",
    "                                   \"umbral_=_0.7_minimo_de_high_en_proximos_15_dias/open(t)\", \"umbral_=_0.7_minimo_de_high_en_proximos_20_dias/open(t)\",\n",
    "                                   \"umbral_=_0.7_minimo_de_high_en_proximos_30_dias/open(t)\", \"umbral_=_0.7_minimo_de_high_en_proximos_40_dias/open(t)\",\n",
    "                                   \"umbral_=_0.7_minimo_de_high_en_proximos_60_dias/open(t)\", \"umbral_=_0.85_minimo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.85_minimo_de_high_en_proximos_15_dias/open(t)\", \"umbral_=_0.85_minimo_de_high_en_proximos_20_dias/open(t)\",\n",
    "                                   \"umbral_=_0.85_minimo_de_high_en_proximos_5_dias/open(t)\", \"umbral_=_0.8_minimo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.8_minimo_de_high_en_proximos_15_dias/open(t)\", \"umbral_=_0.8_minimo_de_high_en_proximos_20_dias/open(t)\",\n",
    "                                   \"umbral_=_0.8_minimo_de_high_en_proximos_30_dias/open(t)\", \"umbral_=_0.8_minimo_de_high_en_proximos_40_dias/open(t)\",\n",
    "                                   \"umbral_=_0.8_minimo_de_high_en_proximos_60_dias/open(t)\", \"umbral_=_0.95_minimo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.95_minimo_de_high_en_proximos_5_dias/open(t)\", \"umbral_=_0.9_minimo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.9_minimo_de_high_en_proximos_15_dias/open(t)\", \"umbral_=_0.9_minimo_de_high_en_proximos_20_dias/open(t)\",\n",
    "                                   \"umbral_=_0.9_minimo_de_high_en_proximos_5_dias/open(t)\", \"minimo_de_high_en_proximos_40_dias/open(t)\",\n",
    "                                   \"umbral_=_0.85_minimo_de_high_en_proximos_30_dias/open(t)\", \"umbral_=_0.9_minimo_de_low_en_proximos_15_dias/open(t)\",\n",
    "                                   \"minimo_de_low_en_proximos_30_dias/open(t)\", \"umbral_=_0.8_minimo_de_low_en_proximos_30_dias/open(t)\",\n",
    "                                   \"umbral_=_0.8_minimo_de_high_en_proximos_5_dias/open(t)\", \"umbral_=_0.8_minimo_de_low_en_proximos_10_dias/open(t)\",\n",
    "                                   \"minimo_de_low_en_proximos_5_dias/open(t)\", \"umbral_=_0.85_minimo_de_low_en_proximos_25_dias/open(t)\",\n",
    "                                   \"minimo_de_low_en_proximos_25_dias/open(t)\", \"umbral_=_0.95_minimo_de_low_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.88_minimo_de_low_en_proximos_15_dias/open(t)\", \"umbral_=_0.8_minimo_de_low_en_proximos_20_dias/open(t)\",\n",
    "                                   \"umbral_=_0.85_minimo_de_low_en_proximos_30_dias/open(t)\", \"umbral_=_0.8_minimo_de_high_en_proximos_25_dias/open(t)\",\n",
    "                                   \"minimo_de_low_en_proximos_20_dias/open(t)\", \"umbral_=_0.8_minimo_de_low_en_proximos_5_dias/open(t)\",\n",
    "                                   \"umbral_=_0.9_minimo_de_high_en_proximos_25_dias/open(t)\", \"umbral_=_0.85_minimo_de_low_en_proximos_5_dias/open(t)\",\n",
    "                                   \"minimo_de_low_en_proximos_10_dias/open(t)\", \"umbral_=_0.9_minimo_de_low_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.85_minimo_de_low_en_proximos_10_dias/open(t)\", \"umbral_=_0.9_minimo_de_low_en_proximos_30_dias/open(t)\",\n",
    "                                   \"umbral_=_0.95_minimo_de_low_en_proximos_5_dias/open(t)\", \"umbral_=_0.9_minimo_de_low_en_proximos_20_dias/open(t)\",\n",
    "                                   \"minimo_de_low_en_proximos_60_dias/open(t)\", \"umbral_=_0.9_minimo_de_low_en_proximos_5_dias/open(t)\",\n",
    "                                   \"umbral_=_0.88_minimo_de_low_en_proximos_5_dias/open(t)\", \"umbral_=_0.85_minimo_de_low_en_proximos_20_dias/open(t)\",\n",
    "                                   \"umbral_=_0.9_minimo_de_low_en_proximos_25_dias/open(t)\", \"umbral_=_0.85_minimo_de_low_en_proximos_15_dias/open(t)\",\n",
    "                                   \"minimo_de_low_en_proximos_40_dias/open(t)\", \"umbral_=_0.88_minimo_de_low_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.8_minimo_de_low_en_proximos_25_dias/open(t)\", \"umbral_=_0.8_minimo_de_low_en_proximos_15_dias/open(t)\",\n",
    "                                   \"umbral_=_0.88_minimo_de_low_en_proximos_20_dias/open(t)\", \"umbral_=_0.85_minimo_de_high_en_proximos_25_dias/open(t)\",\n",
    "                                   \"umbral_=_0.8_minimo_de_low_en_proximos_60_dias/open(t)\", \"minimo_de_high_en_proximos_25_dias/open(t)\",\n",
    "                                   \"umbral_=_0.9_minimo_de_high_en_proximos_30_dias/open(t)\", \"umbral_=_0.8_minimo_de_low_en_proximos_40_dias/open(t)\",\n",
    "                                   \"minimo_de_low_en_proximos_15_dias/open(t)\", \"umbral_=_0.92_minimo_de_low_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.92_minimo_de_low_en_proximos_5_dias/open(t)\", \"umbral_=_0.92_minimo_de_low_en_proximos_15_dias/open(t)\",\n",
    "                                   \"umbral_=_0.92_minimo_de_low_en_proximos_10_dias/open(t)_&_∼_umbral_=_1.06_maximo_de_high_en_proximos_15_dias/open(t)\",\n",
    "                                   \"umbral_=_0.92_minimo_de_low_en_proximos_10_dias/open(t)_&_∼_umbral_=_1.05_maximo_de_high_en_proximos_5_dias/open(t)\",\n",
    "                                   \"umbral_=_0.92_minimo_de_low_en_proximos_10_dias/open(t)_&_∼_umbral_=_1.06_maximo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.9_minimo_de_low_en_proximos_10_dias/open(t)_&_∼_umbral_=_1.06_maximo_de_high_en_proximos_10_dias/open(t)\",\n",
    "                                   \"umbral_=_0.9_minimo_de_low_en_proximos_10_dias/open(t)_&_∼_umbral_=_1.06_maximo_de_high_en_proximos_15_dias/open(t)\",\n",
    "                                   \"umbral_=_0.9_minimo_de_low_en_proximos_10_dias/open(t)_&_∼_umbral_=_1.05_maximo_de_high_en_proximos_5_dias/open(t)\",\n",
    "                                   \"umbral_=_1.3_maximo_de_high_en_proximos_15_dias/open(t)\"\n",
    "                                  } \n",
    "\n",
    "# El set \"variables_dependientes\" sale de unir los conjuntos de las Variables Target Intradiarias y las Variables Target de Largo Plazo:\n",
    "variables_dependientes = variables_target_intradiarias.union(variables_target_de_largo_plazo)\n",
    "\n",
    "variables_todas = set(data.columns)\n",
    "\n",
    "# El set \"variables_independientes\" se obtiene de agarrar todas las variables y restar los conjuntos de las Variables NO Utilizadas para Entrenar y \n",
    "# las Variables Dependientes:\n",
    "variables_independientes = variables_todas - variables_no_utilizadas_para_entrenar.union(variables_dependientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "5p5RTajkLdzf"
   },
   "outputs": [],
   "source": [
    "# Chequeamos que no haya variables futuras en el set 'variables_independientes':\n",
    "chequeo_ausencia_de_variables_futuras_en_las_variables_independientes(variables_independientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "0nQtrpTZb8UB"
   },
   "outputs": [],
   "source": [
    "# Exportamos las listas de variables en formato 'pickle' para que puedan ser leídas por otros archivos de código:\n",
    "\n",
    "with open('variables_target_intradiarias.pickle', 'wb') as archivo:\n",
    "    pickle.dump(variables_target_intradiarias, archivo)\n",
    "\n",
    "with open('variables_target_de_largo_plazo.pickle', 'wb') as archivo:\n",
    "    pickle.dump(variables_target_de_largo_plazo, archivo)\n",
    "\n",
    "with open('variables_independientes.pickle', 'wb') as archivo:\n",
    "    pickle.dump(variables_independientes, archivo)\n",
    "    \n",
    "with open('variables_dependientes.pickle', 'wb') as archivo:\n",
    "    pickle.dump(variables_dependientes, archivo)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7fvV2Gw3sV2"
   },
   "source": [
    "## Filtrado por Fecha y Tratamiento de NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos únicamente con los datos entre los días 2010-07-01 y 2020-06-30:\n",
    "data = data[data.fecha >= pd.to_datetime(datetime.date(2010, 7, 1))]\n",
    "data = data[data.fecha < pd.to_datetime(datetime.date(2022, 7, 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de los NaN:\n",
    "\n",
    "# Identificamos la cantidad de filas que tienen valores NaN:\n",
    "cantidad_de_filas_con_NaN = len(data[data.isnull().any(axis=1)])\n",
    "print(\"La cantidad de filas que tienen valores NaN es:\", cantidad_de_filas_con_NaN)\n",
    "\n",
    "if cantidad_de_filas_con_NaN != 0:\n",
    "  \n",
    "  # Eliminamos del DataFrame aquellas filas con valores NaN:\n",
    "  lista_de_index_con_NaN = data[data.isnull().any(axis=1)].index\n",
    "  data = data.drop(lista_de_index_con_NaN, axis=0)\n",
    "  print(\"Estas filas han sido eliminadas del DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_y_test = data[data.fecha < pd.to_datetime(datetime.date(2020, 7, 1))].copy()\n",
    "\n",
    "# Ordenamos por \"fecha\" y por \"titulo\":\n",
    "data_train_y_test = data_train_y_test.sort_values(by=[\"fecha\", \"titulo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_periodo_subsiguiente = data[data.fecha >= pd.to_datetime(datetime.date(2020, 7, 1))].copy()\n",
    "\n",
    "# Ordenamos por \"fecha\" y por \"titulo\":\n",
    "data_periodo_subsiguiente = data_periodo_subsiguiente.sort_values(by=[\"fecha\", \"titulo\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfonMiudVs4w"
   },
   "source": [
    "## Exportación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_de_guardado = \".\\\\2. Preprocesado de Datos\\\\\"\n",
    "nombre_del_archivo_train_y_test = 'Datos_Completos_Preprocesados'\n",
    "nombre_del_archivo_periodo_subsiguiente = 'Datos_Completos_Preprocesados_Periodo_subsiguiente'\n",
    "extension_del_archivo = '.csv'\n",
    "\n",
    "# Exportamos:\n",
    "data_train_y_test.to_csv( (ruta_de_guardado + nombre_del_archivo_train_y_test + agregado_al_nombre_del_archivo + extension_del_archivo), index = False )\n",
    "data_periodo_subsiguiente.to_csv( (ruta_de_guardado + nombre_del_archivo_periodo_subsiguiente + agregado_al_nombre_del_archivo + extension_del_archivo), index = False )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
